{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sV2NUYLWm_u9"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import sys\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(optional) Get datasets from github repo"
      ],
      "metadata": {
        "id": "pLlUBzZzRBSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access github repo\n",
        "REPO_URL = \"https://github.com/cchen744/CornYield_NN.git\"\n",
        "REPO_NAME = \"CornYield_NN\" # This is the folder name that will be created\n",
        "\n",
        "# 4. Clone the repository\n",
        "# We use the token for secure, authenticated access\n",
        "!git clone https://github.com/cchen744/CornYield_NN.git\n",
        "\n",
        "# 5. Change the working directory into the cloned repository folder\n",
        "import os\n",
        "os.chdir(REPO_NAME)\n",
        "\n",
        "# Verify the files are there (you should see your notebook and dataset files)\n",
        "print(f\"Current directory contents in /{REPO_NAME}:\")\n",
        "!ls -F"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_hJMTKeRE5h",
        "outputId": "066ed091-b4d7-4b2d-9ef2-0a5910b905cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'CornYield_NN'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 33 (delta 12), reused 23 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (33/33), 1.71 MiB | 5.85 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n",
            "Current directory contents in /CornYield_NN:\n",
            "counties.csv\t\tprism_weather_1984-1994.csv  soil_data.csv\n",
            "final_dataset.csv\tprism_weather_1995-2009.csv  weather_clean.csv\n",
            "get_data.ipynb\t\tprism_weather_2010-2024.csv  yield_clean.csv\n",
            "LSTM_+_MLP_model.ipynb\tprism_weather.csv\t     yield.csv\n",
            "nasa_weather.csv\tsoil_clean.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset preparation"
      ],
      "metadata": {
        "id": "LtRq2domcRyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 3 types of datasets:\n",
        "1. yield data, which looks like: <br>\n",
        "Year, County, Yield\n",
        "2. monthly weather data, which looks like: <br>\n",
        "County, Year, Month, solar_radiation, humidity, ...., vpd_max\n",
        "3. soil dataset: <br>\n",
        "County, bdod, cec, ...."
      ],
      "metadata": {
        "id": "nqu244tXaGeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load 3 datasets\n",
        "yield_df_path = \"/content/CornYield_NN/yield_clean.csv\"\n",
        "soil_df_path = \"/content/CornYield_NN/soil_clean.csv\"\n",
        "weather_df_path = \"/content/CornYield_NN/weather_clean.csv\"\n",
        "yield_df = pd.read_csv(yield_df_path)\n",
        "soil_df = pd.read_csv(soil_df_path)\n",
        "weather_df = pd.read_csv(weather_df_path)\n",
        "print(yield_df.head())\n",
        "print(soil_df.head())\n",
        "print(weather_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKZgYQXIbNla",
        "outputId": "2bf91e37-5723-42dd-8bd3-06ccadc5b90f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Year      County  Yield\n",
            "0  2024       adams  120.1\n",
            "1  2024  green lake  168.3\n",
            "2  2024      juneau  141.0\n",
            "3  2024   marquette  126.0\n",
            "4  2024     portage  159.5\n",
            "     County  bdod  cec  clay  nitrogen  phh2o  sand  silt  soc\n",
            "0     adams   132  163   192       698     60   489   319  375\n",
            "1   ashland   115  249   258       601     51   216   526  605\n",
            "2    barron   133  150   185       516     55   317   498  677\n",
            "3  bayfield   111  266   187       545     50   480   333  668\n",
            "4     brown   134  289   308       781     66   328   364  429\n",
            "  County  Year  Month  solar_radiation  humidity  wind_speed  wind_speed_max  \\\n",
            "0  adams  1984      4            16.85     75.80        4.40           12.36   \n",
            "1  adams  1984      5            17.63     74.25        3.26            9.64   \n",
            "2  adams  1984      6            20.75     78.96        3.42            9.15   \n",
            "3  adams  1984      7            21.90     74.48        2.68            8.19   \n",
            "4  adams  1984      8            18.52     68.76        2.31            6.40   \n",
            "\n",
            "   precip  temp_min  temp_mean  temp_max  dewpoint_mean  vpd_min  vpd_max  \n",
            "0    3.83      35.5       46.5      57.5           29.7     1.57    10.85  \n",
            "1    2.27      41.4       53.7      65.9           40.2     1.12    13.40  \n",
            "2    5.96      56.2       68.1      80.0           57.0     1.20    18.43  \n",
            "3    3.29      56.9       69.4      81.9           58.0     1.08    20.90  \n",
            "4    2.54      58.5       70.9      83.2           60.5     0.85    20.17  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want the dataset put into LSTM has the format:<br>\n",
        "(batch_size,num_months,num_features)"
      ],
      "metadata": {
        "id": "FT7Z3z3yNnax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare monthly sequences\n",
        "\n",
        "# Select monthly columns for LSTM\n",
        "monthly_features = weather_df.columns[3:]\n",
        "# Sort and group monthly dataset by (County, Year)\n",
        "grouped_weather = (weather_df\n",
        "    .sort_values([\"County\", \"Year\", \"Month\"])\n",
        "    .groupby([\"County\", \"Year\"])\n",
        ")\n",
        "\n",
        "# Build dictionary: key = (county, year), value = monthly sequence array\n",
        "monthly_weather_dict = {}\n",
        "\n",
        "for (county, year), g in grouped_weather:\n",
        "    seq = g[monthly_features].values  # shape = (num_months, num_features)\n",
        "    monthly_weather_dict[(county, year)] = seq\n",
        "\n",
        "# Show an example\n",
        "first_key = list(monthly_weather_dict.keys())[0]\n",
        "print(\"Example key:\", first_key)\n",
        "print(\"Sequence shape:\", monthly_weather_dict[first_key].shape)\n",
        "print(monthly_weather_dict[first_key][:3])  # first 3 months\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9-xh820Nk9e",
        "outputId": "5c839c35-7aa4-47e3-fad6-cdf91ce39215"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example key: ('adams', np.int64(1984))\n",
            "Sequence shape: (6, 11)\n",
            "[[16.85 75.8   4.4  12.36  3.83 35.5  46.5  57.5  29.7   1.57 10.85]\n",
            " [17.63 74.25  3.26  9.64  2.27 41.4  53.7  65.9  40.2   1.12 13.4 ]\n",
            " [20.75 78.96  3.42  9.15  5.96 56.2  68.1  80.   57.    1.2  18.43]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train test split"
      ],
      "metadata": {
        "id": "VeW1_TRUQ3KY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all (county, year) pairs with yield + weather keys, store keys in a list\n",
        "all_keys = list(monthly_weather_dict.keys())\n",
        "# Perform train_test_split on key_list\n",
        "train_keys, test_keys = train_test_split(all_keys, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ZoguXGEBTzrs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset preparations -- GitHub\n",
        "class YieldDataset(Dataset):\n",
        "    def __init__(self, keys, yield_df, soil_df, weather_dict):\n",
        "        self.keys = keys\n",
        "        self.yield_df = yield_df\n",
        "        self.soil_df = soil_df\n",
        "        self.weather_dict = weather_dict\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.keys)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      county, year = self.keys[idx]\n",
        "      # get weather\n",
        "      seq = self.weather_dict[(county, year)] # shape: (n_month,n_features)\n",
        "      seq = torch.tensor(seq, dtype=torch.float32)\n",
        "      # get yield\n",
        "      y = self.yield_df[\n",
        "      (self.yield_df[\"County\"]==county) &\n",
        "       (self.yield_df[\"Year\"]==year)][\"Yield\"].values[0]\n",
        "      # get soil\n",
        "      soil_row = self.soil_df[self.soil_df[\"County\"] == county].iloc[0]\n",
        "      soil_vec = soil_row.drop(\"County\").values\n",
        "      soil_vec = torch.tensor(soil_vec, dtype=torch.float32) # shape: (n_soil_featuresï¼Œ)\n",
        "\n",
        "      return seq, soil_vec, torch.tensor([y], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "YvRwn-7DpiTm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoader\n",
        "batch_size = 32\n",
        "train_dataset = YieldDataset(train_keys, yield_df, soil_df, monthly_weather_dict)\n",
        "test_dataset = YieldDataset(test_keys, yield_df, soil_df, monthly_weather_dict)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "I8VecCmLZYfm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "# Model assumes that there is at least 1 dimension in monthly, yearly, and static\n",
        "class YieldLSTMMLPConnected(nn.Module):\n",
        "    def __init__(self,\n",
        "                    monthly_dim=7,     # Avg's by month (seq features, should be 7 features from prism data)\n",
        "                    monthly_hidden=64,\n",
        "                    monthly_layers=1,\n",
        "                    yearly_dim=5,    # number of yearly features (should be 5 features, 4 from nasa + the annual yield by county)\n",
        "                    static_dim=8,    # number of static features (should be 8 features from soil data)\n",
        "                    yearly_hidden=32,\n",
        "                    static_hidden=32,\n",
        "                    head_hidden=64,\n",
        "                    output_dim=1,\n",
        "                    dropout=0.1\n",
        "                    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Monthly branch LSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=monthly_dim,\n",
        "            hidden_size=monthly_hidden,\n",
        "            num_layers=monthly_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=False\n",
        "        )\n",
        "        self.monthly_proj = nn.Sequential(\n",
        "            nn.Linear(monthly_hidden, monthly_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # Yearly branch MLP\n",
        "        self.yearly_proj = nn.Sequential(\n",
        "            nn.Linear(yearly_dim, yearly_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(yearly_hidden, yearly_hidden),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # Static branch MLP\n",
        "        self.static_proj = nn.Sequential(\n",
        "            nn.Linear(static_dim, static_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(static_hidden, static_hidden),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # Combined head (output of combined branches)\n",
        "        combined_dim = monthly_hidden + yearly_hidden + static_hidden\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(combined_dim, head_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Droput(dropout),\n",
        "            nn.Linear(head_hidden, head_hidden//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(head_hidden//2, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, monthly, yearly, static):\n",
        "        feats = []\n",
        "\n",
        "        # Monthly shape (batch, seq_len, monthly_dim)\n",
        "        # LSTM: take last hidden state\n",
        "        lstm_out, (h_n, c_n) = self.lstm(monthly)\n",
        "        # h_n shape: (num_layers, batch, hidden)\n",
        "        last_h = h_n[-1] # (batch, monthly_hidden)\n",
        "        monthly_emb = self.monthly_proj(last_h)\n",
        "        feats.append(monthly_emb)\n",
        "\n",
        "        feats.append(self.yearly_proj(yearly))\n",
        "\n",
        "        feats.append(self.static_proj(static))\n",
        "\n",
        "        combined = torch.cat(feats, dim=1)\n",
        "        out = self.head(combined)\n",
        "        return out"
      ],
      "metadata": {
        "id": "ziySIDb4pdtc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    num_epochs=50,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-5,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    early_stop_patience=8\n",
        "):\n",
        "\n",
        "    model = model.to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        # -------- TRAIN MODE --------\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "\n",
        "        for monthly, yearly, static, target in train_loader:\n",
        "            monthly = monthly.to(device)\n",
        "            yearly = yearly.to(device)\n",
        "            static = static.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(monthly, yearly, static)\n",
        "\n",
        "            loss = criterion(preds, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        # -------- VAL MODE --------\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for monthly, yearly, static, target in val_loader:\n",
        "                monthly = monthly.to(device)\n",
        "                yearly = yearly.to(device)\n",
        "                static = static.to(device)\n",
        "                target = target.to(device)\n",
        "\n",
        "                preds = model(monthly, yearly, static)\n",
        "                loss = criterion(preds, target)\n",
        "                val_losses.append(loss.item())\n",
        "\n",
        "        train_loss = np.mean(train_losses)\n",
        "        val_loss = np.mean(val_losses)\n",
        "\n",
        "        print(f\"Epoch {epoch:03d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # ---- EARLY STOP ----\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), \"best_yield_model.pt\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= early_stop_patience:\n",
        "                print(\"Early stopping triggered!\")\n",
        "                break\n",
        "\n",
        "    print(\"Training completed. Best model saved as best_yield_model.pt\")"
      ],
      "metadata": {
        "id": "R2pZ_cYepoKh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pJOJtZjyZW9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T4oChuLgDbEb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}