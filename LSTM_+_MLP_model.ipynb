{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sV2NUYLWm_u9"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset preparations -- GitHub"
      ],
      "metadata": {
        "id": "YvRwn-7DpiTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "# Model assumes that there is at least 1 dimension in monthly, yearly, and static\n",
        "class YieldLSTMMLPConnected(nn.Module):\n",
        "    def __init__(self,\n",
        "                    monthly_dim=7,     # Avg's by month (seq features, should be 7 features from prism data)\n",
        "                    monthly_hidden=64,\n",
        "                    monthly_layers=1,\n",
        "                    yearly_dim=5,    # number of yearly features (should be 5 features, 4 from nasa + the annual yield by county)\n",
        "                    static_dim=8,    # number of static features (should be 8 features from soil data)\n",
        "                    yearly_hidden=32,\n",
        "                    static_hidden=32,\n",
        "                    head_hidden=64,\n",
        "                    output_dim=1,\n",
        "                    dropout=0.1\n",
        "                    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Monthly branch LSTM\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=monthly_dim,\n",
        "            hidden_size=monthly_hidden,\n",
        "            num_layers=monthly_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=False\n",
        "        )\n",
        "        self.monthly_proj = nn.Sequential(\n",
        "            nn.Linear(monthly_hidden, monthly_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "        # Yearly branch MLP\n",
        "        self.yearly_proj = nn.Sequential(\n",
        "            nn.Linear(yearly_dim, yearly_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(yearly_hidden, yearly_hidden),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # Static branch MLP\n",
        "        self.static_proj = nn.Sequential(\n",
        "            nn.Linear(static_dim, static_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(static_hidden, static_hidden),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        # Combined head (output of combined branches)\n",
        "        combined_dim = monthly_hidden + yearly_hidden + static_hidden\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(combined_dim, head_hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Droput(dropout),\n",
        "            nn.Linear(head_hidden, head_hidden//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(head_hidden//2, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, monthly, yearly, static):\n",
        "        feats = []\n",
        "\n",
        "        # Monthly shape (batch, seq_len, monthly_dim)\n",
        "        # LSTM: take last hidden state\n",
        "        lstm_out, (h_n, c_n) = self.lstm(monthly)\n",
        "        # h_n shape: (num_layers, batch, hidden)\n",
        "        last_h = h_n[-1] # (batch, monthly_hidden)\n",
        "        monthly_emb = self.monthly_proj(last_h)\n",
        "        feats.append(monthly_emb)\n",
        "\n",
        "        feats.append(self.yearly_proj(yearly))\n",
        "\n",
        "        feats.append(self.static_proj(static))\n",
        "\n",
        "        combined = torch.cat(feats, dim=1)\n",
        "        out = self.head(combined)\n",
        "        return out"
      ],
      "metadata": {
        "id": "ziySIDb4pdtc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "R2pZ_cYepoKh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}